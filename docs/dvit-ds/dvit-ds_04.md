## 第四章：A/B 测试

![](img/chapterart.png)

在上一章中，我们讨论了观察两个群体并对它们之间的关系做出定量判断的科学实践。但科学家（包括数据科学家）不仅仅是观察已有的差异。科学的一个重要部分是通过实验制造差异，然后得出结论。在本章中，我们将讨论如何在商业中进行这些类型的实验。

我们将从讨论实验的必要性和我们进行测试的动机开始。我们将涵盖如何正确设置实验，包括随机化的必要性。接下来，我们将详细介绍 A/B 测试和冠军/挑战者框架的步骤。最后，我们将描述一些细微差别，比如探索/利用的权衡，以及伦理问题。

## 实验的必要性

让我们回到第三章下半部分概述的情境。假设你经营一家电脑公司，并维护着客户可以选择订阅的电子邮件营销列表。一个电子邮件列表是为对台式机感兴趣的客户设计的，另一个电子邮件列表是为对笔记本电脑感兴趣的客户设计的。你可以从[`bradfordtuckfield.com/desktop.csv`](https://bradfordtuckfield.com/desktop.csv)和[`bradfordtuckfield.com/laptop.csv`](https://bradfordtuckfield.com/laptop.csv)下载两个虚构的数据集。如果你将它们保存在你运行 Python 的相同目录下，你可以如下方式将这些假设的列表读取到 Python 中：

```py
import pandas as pd
desktop=pd.read_csv('desktop.csv')
laptop=pd.read_csv('laptop.csv')
```

你可以运行`print(desktop.head())`和`print(laptop.head())`来查看每个数据集的前五行。

在第三章中，你学会了如何使用简单的 t 检验来检测我们的数据集之间的差异，具体如下：

```py
import scipy.stats
print(scipy.stats.ttest_ind(desktop['spending'],laptop['spending']))
print(scipy.stats.ttest_ind(desktop['age'],laptop['age']))
print(scipy.stats.ttest_ind(desktop['visits'],laptop['visits']))
```

在这里，我们导入 SciPy 包的`stats`模块，以便使用 t 检验。然后我们打印三个独立 t 检验的结果：一个比较台式机和笔记本电脑订阅者的消费，一个比较台式机和笔记本电脑订阅者的年龄，一个比较台式机和笔记本电脑订阅者的记录网站访问次数。我们可以看到，第一个*p*值小于 0.05，这表明这两个群体在消费水平上存在显著差异（在 5%的显著性水平下），正如我们在第三章中得出的结论。

在确定台式机订阅者与笔记本电脑订阅者有所不同之后，我们可以得出结论，应该向他们发送不同的营销邮件。然而，仅凭这一事实并不足以完全指导我们的营销策略。仅仅知道我们的台式机订阅者群体的消费略低于笔记本电脑订阅者群体，并不能告诉我们，长篇信息或短篇信息哪种更能促进销售，或者使用红色文本还是蓝色文本能获得更多的点击，或者使用非正式语言还是正式语言能更好地提升客户忠诚度。在某些情况下，学术营销期刊中发布的过往研究可以为我们提供有效的线索。但即便存在相关的研究，每个公司都有其独特的客户群，这些客户群可能不会像过往研究所示那样对营销产生反应。

我们需要一种方法来生成以前从未收集或发布过的新数据，这样我们才能利用这些数据来回答有关我们常常面临的新情况的问题。只有能够生成这种新数据，我们才能可靠地了解在面对我们特定的独特客户群时，哪些方法最能推动我们的业务增长。本章剩余的部分将讨论一种可以实现这一目标的方法。

*A/B 测试*，本章的重点，使用实验来帮助企业确定哪些做法能为它们带来最大的成功机会。它包含几个步骤：实验设计、将样本随机分配到实验组和控制组、仔细衡量结果，最后对各组之间的结果进行统计比较。

我们将采用的统计比较方法应该是熟悉的：我们将使用上一章介绍的 t 检验。虽然 t 检验是 A/B 测试的一部分，但它并不是唯一的部分。A/B 测试是一个收集新数据的过程，这些数据可以通过 t 检验等方法进行分析。由于我们已经介绍了 t 检验，因此本章不会再重点讨论它。相反，我们将重点讨论 A/B 测试的其他所有步骤。

## 进行实验以测试新假设

让我们考虑一个关于我们客户的假设，这可能引起我们的兴趣。假设我们想研究是否将我们营销邮件中的文本颜色从黑色改为蓝色会增加我们从这些邮件中获得的收入。我们可以提出与此相关的两个假设：

假设 0：将我们电子邮件中的文本颜色从黑色改为蓝色不会对收入产生任何影响。

假设 1：将我们电子邮件中的文本颜色从黑色改为蓝色将会导致收入发生变化（无论是增加还是减少）。

我们可以使用第三章中介绍的假设检验框架来检验原假设（假设 0），并决定是否要拒绝它，转而接受其替代假设（假设 1）。唯一的区别是，在第三章中，我们检验的是已经收集的数据相关的假设。而在这里，我们的数据集并不包括关于蓝色文本和黑色文本电子邮件的信息。因此，在进行假设检验之前需要额外的步骤：设计实验、进行实验，并收集与实验结果相关的数据。

进行实验可能听起来不那么困难，但一些关键的细节非常重要，需要做到精准无误。为了进行我们刚才提到的假设检验，我们需要来自两个组的数据：一个收到蓝色文本电子邮件的组和一个收到黑色文本电子邮件的组。我们需要知道从收到蓝色文本电子邮件的每个组成员那里获得了多少收入，以及从收到黑色文本电子邮件的每个组成员那里获得了多少收入。

在我们有了这些数据之后，我们可以做一个简单的 t 检验，以确定蓝色文本组收集的收入是否与黑色文本组收集的收入有显著差异。在本章中，我们将对所有测试使用 5%的显著性水平——也就是说，如果我们的*p*-值小于 0.05，我们将拒绝原假设并接受替代假设。如果我们进行 t 检验，发现收入差异显著，我们可以拒绝原假设（假设 0）。否则，我们不会拒绝原假设，并且在没有其他证据的情况下，我们将接受其关于蓝色和黑色文本产生相等收入的断言。

我们需要将目标人群分成两个子组，向一个子组发送蓝色文本电子邮件，向另一个子组发送黑色文本电子邮件，这样我们就可以比较每个组的收入。现在，先让我们只关注桌面端订阅者，并将我们的桌面数据框分为两个子组。

我们可以通过多种方式将一个组分成两个子组。一个可能的选择是将我们的数据集分为年轻人组和老年人组。我们可能这样划分数据，因为我们认为年轻人和老年人可能对不同的产品感兴趣，或者我们可能仅仅因为年龄是我们数据中少数几个变量之一而这么做。稍后我们将看到，这种将组分成子组的方法会在我们的分析中引发问题，我们将讨论更好的创建子组的方法。但由于这种分组方法简单易行，让我们先尝试一下，看看会发生什么：

```py
import numpy as np
medianage=np.median(desktop['age'])
groupa=desktop.loc[desktop['age']<=medianage,:]
groupb=desktop.loc[desktop['age']>medianage,:]
```

这里，我们导入了 NumPy 包，并为其指定别名`np`，以便使用它的`median()`方法。然后，我们简单地取出桌面订阅者组的中位年龄，并创建`groupa`，它是一个年龄小于或等于中位年龄的桌面订阅者子集；`groupb`是一个年龄高于中位年龄的桌面订阅者子集。

在创建了`groupa`和`groupb`之后，你可以将这两个数据框发送给你的营销团队成员，并指示他们向每个组发送不同的邮件。假设他们将黑色文本的邮件发送给`groupa`，将蓝色文本的邮件发送给`groupb`。每封邮件中都会包含他们想要销售的新产品链接，通过跟踪谁点击了哪些链接以及他们的购买情况，团队成员可以衡量每个邮件接收者带来的总收入。

让我们读取一些虚构的数据，这些数据展示了我们两个组成员的假设结果。你可以从[`bradfordtuckfield.com/emailresults1.csv`](https://bradfordtuckfield.com/emailresults1.csv)下载这些数据；并将其存储在你运行 Python 的同一目录下。然后，你可以按如下方式将其读取到 Python 会话中：

```py
emailresults1=pd.read_csv('emailresults1.csv')
```

如果你在 Python 中运行`print(emailresults1.head())`，你可以看到这组新数据的前几行。这是一个简单的数据集：每一行对应一个个人桌面邮件订阅者，其 ID 在`userid`列中标识。`revenue`列记录了你公司通过这次电子邮件活动从每个用户那里获得的收入。

将这些新的收入信息与我们关于每个用户的其他信息放在同一个数据框中是非常有用的。让我们合并这些数据集：

```py
groupa_withrevenue=groupa.merge(emailresults1,on='userid')
groupb_withrevenue=groupb.merge(emailresults1,on='userid')
```

在这个代码片段中，我们使用 pandas 的`merge()`方法来合并数据框。我们指定`on='userid'`，这意味着我们将`emailresults1`中与特定`userid`对应的行与`groupa`中与该`userid`相对应的行合并。使用`merge()`的最终结果是一个数据框，其中每一行对应一个通过其唯一`userid`识别的用户。列中不仅告诉我们关于用户的特征（如年龄），还告诉我们通过最近的电子邮件活动从他们那里获得的收入。

在准备好数据之后，进行 t 检验来检查我们的组是否有差异变得简单。我们可以通过一行代码来完成，如下所示：

```py
print(scipy.stats.ttest_ind(groupa_withrevenue['revenue'],groupb_withrevenue['revenue']))
```

当你运行这段代码时，你将得到如下结果：

```py
Ttest_indResult(statistic=-2.186454851070545, pvalue=0.03730073920038287)
```

输出中重要的部分是`pvalue`变量，它告诉我们测试的*p*-值。我们可以看到结果显示*p* ≈ 0.037。由于*p* < 0.05，我们可以得出结论，这是一种具有统计学意义的差异。我们可以检查差异的大小：

```py
print(np.mean(groupb_withrevenue['revenue'])-np.mean(groupa_withrevenue['revenue']))
```

输出结果是 125.0。平均而言，`groupb` 的客户比 `groupa` 的客户多花费了 $125。这一差异在统计学上具有显著性，因此我们拒绝零假设，支持假设一，得出结论（至少目前为止）认为营销邮件中的蓝色文本使每个用户的收入比黑色文本多出约 $125。

我们刚刚做的是一个*实验*。我们将一个人群分成两组，对每组进行不同的处理，并比较结果。在商业环境中，这种实验通常被称为 *A/B 测试*。名称中的 *A/B* 部分指的是两组，A 组和 B 组，我们比较了它们对电子邮件的不同反应。每个 A/B 测试遵循我们这里经历的相同模式：将人群分成两组，对每组施加不同的处理（例如，发送不同的电子邮件），并通过统计分析比较两组的结果，得出哪个处理更好的结论。

现在我们已经成功进行了 A/B 测试，我们可能会得出结论，蓝色文本的效果是增加 $125 的支出。然而，我们进行的 A/B 测试存在问题：它是*混淆的*。为了更好地理解这一点，参考 表 4-1。

表 4-1：组间差异

|  | **A 组** | **B 组** |
| --- | --- | --- |
| **个人特征** | 年轻（其他方面与 B 组相同） | 年长（其他方面与 A 组相同） |
| **电子邮件文本颜色** | 黑色 | 蓝色 |
| **每用户平均收入** | $104 | $229 |

我们可以看到 A 组和 B 组的重要特征。我们通过 t 检验比较了它们的支出，结果发现它们的支出水平有显著差异。我们想要解释为什么它们的支出不同，任何对不同结果的解释都必须依赖于 表 4-1 中列出的差异。我们希望得出结论，支出差异可以通过文本颜色的不同来解释。然而，这种差异与另一个差异并存：年龄。

我们不能确定支出水平的差异是由文本颜色引起的，而不是由年龄差异引起的。例如，也许根本没有人注意到文本颜色的不同，但年长的人通常比年轻人更富有，也更愿意购买你的产品。如果真是这样，那么我们的 A/B 测试并不是在测试蓝色文本的效果，而是在测试年龄或财富的影响。我们原本只打算研究文本颜色的影响，但现在我们不知道到底是在研究文本颜色，还是在研究年龄、财富，或者其他因素。如果我们的 A/B 测试有一个更简单、不带混淆因素的设计，像 表 4-2 中所示的那样，那就更好了。

表 4-2：一个无混淆的 A/B 测试设计

|  | **C 组** | **D 组** |
| --- | --- | --- |
| **个人特征** | （与 D 组完全相同） | （与 C 组完全相同） |
| **电子邮件文本颜色** | 黑色 | 蓝色 |
| **每用户平均收入** | $104 | $229 |

表格 4-2 假设我们将用户分成了两个假设的组，C 组和 D 组，这两个组在所有个人特征上都是相同的，唯一的区别是他们收到的邮件文本不同。在这个假设场景下，消费差异只能通过不同的文本颜色来解释，因为这是它们之间唯一的区别。我们应该以一种确保组与组之间唯一差异来自实验处理，而非组成员先前特征的方式来分组。如果我们这么做了，就能避免实验中的混杂效应。

### 理解 A/B 测试中的数学原理

我们也可以用数学的方式来表示这些概念。我们可以使用常见的统计符号*E*()来表示期望值。所以*E*(*A 使用黑色文本时的收入*)就表示*我们通过给 A 组发送黑色文本邮件所能获得的期望收入*。我们可以写出两个简单的方程，描述我们期望从黑色文本、实验效应和蓝色文本中获得的收入之间的关系：

*E*(*A 使用黑色文本时的收入*) + *E*(*将黑色文本改为蓝色对 A 的影响*) = *E*(*A 使用蓝色文本时的收入*)

*E*(*B 使用黑色文本时的收入*) + *E*(*将黑色文本改为蓝色对 B 的影响*) = *E*(*B 使用蓝色文本时的收入*)

为了决定是否拒绝假设 0，我们需要求解效应值：*E*(*将黑色文本改为蓝色对 A 的影响*)和*E*(*将黑色文本改为蓝色对 B 的影响*)。如果其中任何一个效应值不为 0，我们就应该拒绝假设 0。通过实验，我们发现*E*(*A 使用黑色文本时的收入*) = 104，*E*(*B 使用蓝色文本时的收入*) = 229。知道这些数值后，我们可以得到以下方程：

104 + *E*(*将黑色文本改为蓝色对 A 的影响*) = *E*(*A 使用蓝色文本时的收入*)

*E*(*B 使用黑色文本时的收入*) + *E*(*将黑色文本改为蓝色对 B 的影响*) = 229

但这仍然存在许多我们不知道的变量，并且我们还无法解出*E*(*将黑色文本改为蓝色对 A 的影响*)和*E*(*将黑色文本改为蓝色对 B 的影响*)。要解决这些效应值，唯一的方法是简化这两个方程。例如，如果我们知道*E*(*A 使用黑色文本时的收入*) = *E*(*B 使用黑色文本时的收入*)，并且*E*(*将黑色文本改为蓝色对 A 的影响*) = *E*(*将黑色文本改为蓝色对 B 的影响*)，且*E*(*A 使用蓝色文本时的收入*) = *E*(*B 使用蓝色文本时的收入*)，那么我们就可以将这两个方程简化为一个简单的方程。如果我们知道实验前我们的组是相同的，那么我们就知道这些期望值都是相等的，从而能够轻松简化我们的两个方程，得到一个可解的方程：

104 + *E*(*将黑色文本改为蓝色对每个人的影响*) = 229

有了这个，我们可以确信蓝色文本的效果是$125 的收入增加。这就是为什么我们认为设计没有混杂因素的实验如此重要，在这些实验中，各组在个人特征上的期望值相等。通过这样做，我们能够解出之前的方程，并且可以自信地认为我们测量的效应大小实际上是我们研究的内容的效应，而不是不同潜在特征的结果。

### 将数学转化为实践

我们知道该如何从数学上处理，但我们需要将其转化为实际行动。我们应该如何确保*E*(*A 使用蓝色文本的收入*) = *E*(*B 使用蓝色文本的收入*)，并且如何确保其他期望值都是相同的？换句话说，我们如何确保我们的研究设计像表格 4-2 而不是表格 4-1？我们需要找到一种方法，从我们的桌面订阅者列表中选择预期相同的子组。

选择预期相同的子组最简单的方法是随机选择。我们在第三章中简要提到过这一点：来自一个总体的每个随机样本，其期望值等于总体均值。因此，我们预期来自同一总体的两个随机样本之间不会有显著差异。

让我们对我们的笔记本电脑订阅者列表进行 A/B 测试，但这次我们将使用随机化来选择我们的组，以避免出现混杂的实验设计。假设在这个新的 A/B 测试中，我们想要测试在营销邮件中添加图片是否会提高收入。我们可以像之前一样进行：我们将笔记本电脑订阅者列表分成两个子组，并向每个子组发送不同的邮件。不同之处在于，这次我们不是根据年龄分组，而是进行随机分组：

```py
np.random.seed(18811015)
laptop.loc[:,'groupassignment1']=1*(np.random.random(len(laptop.index))>0.5)
groupc=laptop.loc[laptop['groupassignment1']==0,:].copy()
groupd=laptop.loc[laptop['groupassignment1']==1,:].copy()
```

在这个代码片段中，我们使用 NumPy 的`random.random()`方法生成一个包含随机生成的 0 和 1 的列。我们可以将 0 解释为用户属于 C 组，而 1 表示用户属于 D 组。当我们像这样随机生成 0 和 1 时，两个组可能会有不同的大小。然而，在这里我们使用了一个*随机种子*（在第一行，`np.random.seed(18811015)`）。每当有人使用这个随机种子时，他们“随机”生成的 0 和 1 列将是相同的。这意味着如果你使用这个随机种子，你在家里得到的结果应该和书中的结果一样。使用随机种子并不是必须的，但如果你使用我们这里使用的相同随机种子，你应该会发现 C 组和 D 组各有 15 个成员。

在生成了一个包含 0 和 1 的随机列，表示每个客户的组别分配后，我们创建了两个更小的数据框，`groupc`和`groupd`，它们包含了每个子组中用户的 ID 和信息。

你可以将群组成员信息发送给你的营销团队成员，并请他们向正确的群组发送相应的邮件。一个群组，可以是 C 组或 D 组，应该收到没有图片的邮件，而另一个群组，可以是 D 组或 C 组，应该收到带有图片的邮件。假设营销团队随后将最新的 A/B 测试结果文件发送给你，你可以从[`bradfordtuckfield.com/emailresults2.csv`](https://bradfordtuckfield.com/emailresults2.csv)下载一个包含假设结果的虚构数据集。在你将数据存储在运行 Python 的同一位置后，接下来让我们按照以下方式将这个邮件活动的结果读取到 Python 中：

```py
emailresults2=pd.read_csv('emailresults2.csv')
```

同样，让我们将邮件结果与群组数据框连接起来，就像我们之前做的那样：

```py
groupc_withrevenue=groupc.merge(emailresults2,on='userid')
groupd_withrevenue=groupd.merge(emailresults2,on='userid')
```

我们还可以使用 t 检验来检查 C 组的收入是否与 D 组的收入不同：

```py
print(scipy.stats.ttest_ind(groupc_withrevenue['revenue'],groupd_withrevenue['revenue']))
```

我们发现*p*-值小于 0.05，这表明两个群组之间的差异具有统计学意义。此次实验没有被混淆，因为我们使用了随机分配，以确保群组之间的差异是由于我们不同的邮件，而不是各组特征的差异。由于我们的实验没有受到混淆，而且我们发现 C 组和 D 组之间的收入差异显著，我们可以得出结论：在邮件中加入图片具有非零的效果。如果营销团队告诉我们他们只将图片发送给了 D 组，我们可以轻松地找出效果的估算大小：

```py
print(np.mean(groupd_withrevenue['revenue'])-np.mean(groupc_withrevenue['revenue']))
```

我们在这里通过减法计算估算的效果：即 D 组参与者获得的平均收入减去 C 组参与者获得的平均收入。C 组与 D 组之间的平均收入差异，约为$260，这就是我们实验效果的大小。

我们进行 A/B 测试的过程其实非常简单，但它也非常强大。我们可以用它来回答各种各样的问题，尤其是那些我们在业务决策中可能遇到的疑问。任何时候，如果你对采取何种方法感到不确定，特别是在用户互动和产品设计方面，考虑采用 A/B 测试作为一种学习答案的方法是值得的。现在你已经了解了这个过程，接下来我们将继续深入了解它的细节。

## 使用冠军/挑战者框架进行优化

当我们制作出一封很棒的邮件时，我们可能会称其为我们的*冠军*邮件设计：根据我们迄今为止所了解的情况，我们认为它的表现会最好。一旦我们有了一个冠军邮件设计，我们可能会想停止进行 A/B 测试，直接停下来，依赖我们“完美”的邮件活动源源不断地收钱。

但这并不是一个好主意，原因有几个。首先，时代在变化。设计和营销的潮流变化很快，一个今天看起来令人兴奋且有效的营销手段，很快可能会变得过时和落后。像所有冠军一样，你的冠军邮件设计会随着时间的推移变得更弱、更无效。即使设计和营销潮流 *没有* 变化，随着新鲜感的消退，你的冠军邮件最终会显得乏味：新的刺激更容易吸引人们的注意。

你不应该停止 A/B 测试的另一个原因是，你的客户群会发生变化。你将失去一些老客户并获得新客户。你会发布新产品并进入新市场。随着客户群体的变化，他们倾向于响应的邮件类型也会发生变化，持续的 A/B 测试将帮助你跟上他们不断变化的特点和偏好。

继续 A/B 测试的另一个原因是，尽管你的冠军邮件可能已经不错，但你可能还没有在所有可能的方面对它进行优化。你尚未测试的某个维度可能会让你拥有一个更优秀的冠军邮件，从而获得更好的表现。如果我们能够成功地进行一次 A/B 测试并学到一些东西，我们自然会希望继续使用 A/B 测试技巧，学到更多，并将利润推向更高。

假设你有一封冠军邮件，并希望继续进行 A/B 测试，以尝试改进它。你再次将用户随机分组，分为新的 A 组和 B 组。你将冠军邮件发送给 A 组。你将另一封与冠军邮件在某个方面有所不同的邮件发送给 B 组，你希望通过这种方式获得一些信息；例如，也许它使用了正式的语言而不是非正式的语言。当我们在邮件活动结束后比较 A 组和 B 组的收入时，我们将能够看出这封新邮件是否比冠军邮件效果更好。

由于这封新邮件与冠军邮件直接竞争，我们称其为 *挑战者*。如果冠军邮件的表现优于挑战者，冠军将保留其冠军地位。如果挑战者的表现优于冠军，那么这个挑战者将成为新的冠军。

这个过程可以无限持续下去：我们拥有一个代表我们所做事情（在这里是营销邮件）最前沿水平的冠军邮件。我们不断通过与一系列挑战者在 A/B 测试中进行直接竞争来测试冠军邮件。每当某个挑战者的结果显著优于冠军邮件时，这个挑战者就会成为新的冠军，并且将与新的挑战者进行后续的竞争。

这个不断进行的过程被称为*冠军/挑战者框架*，用于 A/B 测试。它旨在通过持续改进、不断优化，逐步实现业务各个方面的最佳表现。世界上最大的科技公司每天都进行数百次 A/B 测试，数百个挑战者与数百个冠军对抗，有时会战胜他们，有时会被击败。冠军/挑战者框架是为业务中最重要和最具挑战性的部分设置和运行 A/B 测试的常见方法。

## 通过 Twyman 定律和 A/A 测试防止错误

A/B 测试从头到尾是一个相对简单的过程。然而，我们都是人，难免会犯错。在任何数据科学工作中，不仅仅是 A/B 测试，谨慎行事并不断检查是否存在错误是非常重要的。一个常见的证据，表明我们可能做错了什么，就是事情进展得过于顺利。

如果一切进展顺利，怎么会不好呢？考虑一个简单的例子。你进行了一次 A/B 测试：A 组收到一封电子邮件，B 组收到另一封。然后你衡量了每组的收入，发现 A 组的平均收入大约为$25，而 B 组的平均收入为$99,999。你为 B 组获得的巨大收入感到兴奋。你召集所有同事开紧急会议，告诉他们立即停止手头的工作，立即实施 B 组收到的电子邮件，并围绕这个奇迹般的电子邮件调整公司的整体战略。

当你的同事们日以继夜地将新的电子邮件发送给他们认识的每个人时，你开始感到一种挥之不去的疑虑。你开始思考，单一的电子邮件活动几乎每个收件人就能赚取接近$100,000 的收入，这种情况是多么不太可能，尤其是当你其他的活动每个用户仅赚取大约$25 时。你还想到了$99,999 这个数字——据说你每个用户赚取的收入，它是五个相同的数字重复出现的。也许你还记得曾与一位数据库管理员的对话，他告诉你公司数据库每当出现数据库错误或数据丢失时，系统会自动插入 99999。突然间，你意识到，实际上你的电子邮件活动并没有真的为每个用户赚取$99,999，而是由于 B 组的数据库错误导致了这一看似奇迹般的结果。

从数据科学的角度来看，A/B 测试是一个简单的过程，但从实践和社会角度来看，它可能相当复杂。例如，在任何比微小创业公司更大的公司中，设计营销电子邮件的创意人员与维护记录每个用户收入的数据库的技术人员不同。其他小组可能会参与 A/B 测试中的某些小部分：也许是一个负责维护安排和发送电子邮件软件的小组，也许是一个为电子邮件营销团队制作艺术设计的小组，甚至可能还有其他小组。

在涉及这些小组和步骤的情况下，存在许多可能导致沟通不畅和小错误的机会。也许设计了两封不同的电子邮件，但负责发送的人不了解 A/B 测试，结果将相同的电子邮件复制粘贴到两个小组中。也许他们不小心粘贴了本不应该出现在 A/B 测试中的内容。在我们的例子中，也许记录收入的数据库出现了错误，把 99999 当作错误代码写入结果，其他人误以为这是一个高收入的表现。无论我们如何小心，错误和误解总会找到发生的方式。

错误的不可避免性应该使我们自然地对任何看起来过于好、坏、有趣或奇怪的事物保持怀疑。这种天然的怀疑是*Twyman 法则*所提倡的，法则指出“任何看起来有趣或不同的数字通常是错误的。”这一法则已经以几种不同的方式重新表述过，包括“任何看起来有趣的统计数据几乎肯定是个错误”和“数据越不寻常或有趣，就越可能是错误的结果。”

除了极度小心和对好消息的天然怀疑外，我们还有另一种有效的方式来防止类似*Twyman 法则*所警告的解释性错误：*A/A 测试*。这种测试和字面意思一样；我们按照 A/B 测试中的步骤进行随机化、处理和比较两个小组，但我们不是向两个随机小组发送不同的电子邮件，而是向每个小组发送完全相同的电子邮件。在这种情况下，我们期望零假设成立，并且不会轻易被一个看似获得比另一个小组多$100,000 收入的组所说服。

如果我们一贯发现 A/A 测试在组间产生了统计学上显著的差异，我们可以得出结论：我们的过程存在问题：数据库出现故障、t 检验运行不正确、邮件粘贴错误、随机化执行不当，或者其他问题。A/A 测试还帮助我们意识到本章描述的第一个测试（其中组 A 由年轻人组成，组 B 由老年人组成）是有混淆的，因为我们会知道 A/A 测试结果之间的差异一定是由于年龄差异，而不是邮件之间的差异。A/A 测试可以作为一个有用的理智检查，防止我们被 Twyman 定律警告的那种不寻常、有趣、看似太好以至于不真实的结果所冲昏头脑。

## 理解效应大小

在我们进行的第一次 A/B 测试中，我们观察到组 A（收到黑色文字邮件的用户）和组 B（收到蓝色文字邮件的用户）之间的差异为$125。这个组间的$125 差异也被称为 A/B 测试的*效应大小*。我们自然会尝试判断是否应该将这个$125 的效应大小视为小效应、中效应，还是大效应。

要判断一个效应是小还是大，我们必须将其与其他内容进行比较。考虑以下各国的名义 GDP 数据（以 2019 年为准，单位为美元），分别是马来西亚、缅甸和马绍尔群岛：

```py
gdps=[365303000000,65994000000,220000000]
```

当我们看到这些数字时，$125 开始显得相当小。例如，考虑我们`gdps`列表的标准差：

```py
print(np.std(gdps))
```

结果是 158884197328.32672，约为$158,884,197,328（几乎是 1590 亿美元）。标准差是衡量数据集分散程度的常用方法。如果我们观察到两个国家的 GDP 差异约为 800 亿美元，我们不会认为这个差异是极其大或极其小，因为这意味着这两个国家的 GDP 大约相差一个标准差的一半，这是一个常见的差异规模。与其将差异表示为 800 亿美元的差异，不如说这两个国家的 GDP 相差了大约一个标准差的一半，并且预计任何具备一些统计学训练的人都会理解这一点。

相比之下，如果有人告诉你两个国家的 GDP 差异为 112 万亿缅元（缅甸的货币），如果你从未了解过 1 缅元的价值，你可能不确定这个差异是大还是小（112 万亿缅元大约等于$800 亿美元，按写作时的汇率计算）。世界上存在许多货币，它们的相对和绝对价值一直在变化。而标准差则不会特定于任何某个国家，也不受通货膨胀的影响，因此它是一个有用的衡量单位。

我们也可以在其他领域使用标准差作为衡量标准。来自欧洲的人可能习惯于使用米来表示身高。当你告诉你的欧洲数据科学家朋友某个人身高为 75 英寸时，如果他们不习惯从英寸换算，他们可能会困惑这个身高是高还是矮还是平均。如果你告诉他们这个人比平均值高了大约两个标准差，他们应该立刻明白他挺高的，但并不算破纪录的高度。观察身高比平均值高出三个标准差以上的人将会更为罕见，无论我们是使用米、英寸还是其他单位来衡量，结果都是一样的。

当我们谈论 A/B 测试中的$125 效应大小时，我们也可以尝试从标准差的角度来理解它。与我们所见的 GDP 测量值的标准差相比，$125 只是小菜一碟：

```py
print(125/np.std(gdps))
```

结果大约是 7.9 · 10^（–10），这告诉我们$125 效应大小大约是我们 GDP 数据标准差的十亿分之一。与 GDP 测量的世界相比，$125 的 GDP 差异就像是比你的朋友高出一个微米——没有足够精确的测量技术根本察觉不到。

相反，假设我们对当地餐馆的汉堡价格进行了一项调查。也许我们找到了以下价格：

```py
burgers=[9.0,12.99,10.50]
```

我们也可以检查这个标准差：

```py
print(np.std(burgers))
```

我们的汉堡价格数据的标准差大约是 1.65。所以，两个国家的 GDP 相差约 800 亿美元，和两个汉堡价格相差大约 80 美分大致是相当的：它们分别代表了各自领域中大约一半的标准差。当我们将$125 效应大小与此比较时，我们可以看出它是巨大的：

```py
print(125/np.std(burgers))
```

我们看到$125 大约是 75.9 个汉堡价格的标准差。所以，如果你所在的城市出现了$125 的汉堡价格差异，那就像看到一个超过 20 英尺高的男人——闻所未闻。

通过将我们的效应大小以不同数据集的标准差为单位进行衡量，我们可以轻松地进行比较，不仅可以比较使用相同单位的不同领域（以美元计的 GDP 与以美元计的汉堡价格），还可以比较使用完全不同单位的不同领域（以美元计的汉堡价格与以英寸计的身高）。我们在这里计算过几次的度量——效应大小除以相关标准差——叫做*Cohen's d*，它是衡量效应大小的常用度量。Cohen 的*d*就是两个群体的平均值之间的标准差差距。我们可以通过以下方式计算我们的第一次 A/B 测试的 Cohen 的*d*：

```py
print(125/np.std(emailresults1['revenue']))
```

我们看到结果大约是 0.76。当我们使用 Cohen 的*d*时，通常的约定是，如果 Cohen 的*d*大约为 0.2 或更低，我们认为效果较小；如果 Cohen 的*d*大约为 0.5，我们认为效果中等；如果 Cohen 的*d*大约为 0.8 甚至更高，我们认为效果较大。由于我们的结果大约是 0.76——非常接近 0.8——我们可以说我们正在处理一个大的效果大小。

## 计算数据的显著性

我们通常使用统计显著性作为关键证据，以证明我们在 A/B 测试中研究的效果是真实的。从数学上讲，统计显著性取决于三个因素：

+   被研究的效果大小（比如改变电子邮件文本颜色所带来的收入增加）。更大的效果使统计显著性更有可能出现。

+   被研究的样本大小（比如接收我们营销邮件的订阅者列表中的人数）。更大的样本使统计显著性更有可能出现。

+   我们使用的显著性阈值（通常为 0.05）。更高的阈值使统计显著性更有可能出现。

如果我们有一个较大的样本量，并且研究的是一个较大的效果，我们的 t 检验很可能会达到统计显著性。另一方面，如果我们研究的是一个非常小的效果，且样本非常小，我们可能已经注定了自己的失败：我们检测到统计显著性结果的概率基本为 0——即使电子邮件确实有影响。由于运行 A/B 测试需要时间和金钱，我们宁愿不浪费资源进行这种注定无法达到统计显著性的测试。

正确运行的 A/B 测试拒绝虚无假设的概率被称为 A/B 测试的*统计功效*。如果改变文本颜色导致每位用户的收入增加 125 美元，我们可以说 125 美元是效果大小，且由于效果大小非零，我们知道虚无假设（改变文本颜色对收入没有影响）是错误的。但如果我们仅用三四个电子邮件订阅者的样本来研究这个真实效果，很有可能因为偶然原因，这些订阅者中没有人购买任何东西，因此我们未能发现真实的 125 美元效果。相比之下，如果我们使用一个有百万订阅者的电子邮件列表来研究文本颜色的变化效果，我们更有可能发现 125 美元的效果并将其测量为统计显著。对于百万订阅者列表，我们具有更大的统计功效。

我们可以导入一个 Python 模块，使得计算统计功效变得简单：

```py
from statsmodels.stats.power import TTestIndPower
```

为了使用这个模块计算统计功效，我们需要定义影响统计显著性的三个因素的参数（参见前面的要点列表）。我们将定义`alpha`，即我们选择的统计显著性阈值，正如第三章所讨论的那样：

```py
alpha=0.05
```

我们选择了标准的 0.05 阈值作为`alpha`，这是许多实证研究中常见的做法。我们还需要定义我们的样本大小。假设我们正在对一组由 90 名电子邮件订阅者组成的群体进行 A/B 测试。这意味着 A 组和 B 组各有 45 人，因此我们将每组的观测数量定义为 45。我们会将这个数字存储在一个名为`nobs`的变量中，`nobs`是*观测数量*的缩写：

```py
nobs=45
```

我们还需要定义一个估计的效应大小。在我们之前的 A/B 测试中，我们观察到的效应大小为$125。然而，对于该模块执行的统计功效计算，我们不能以美元或任何其他货币单位来表达效应大小。我们将改用 Cohen 的*d*，并指定一个中等大小：

```py
effectsize=0.5
```

最后，我们可以使用一个函数，它将接受我们定义的三个参数，并计算我们应该预期的统计功效：

```py
analysis = TTestIndPower()
power = analysis.solve_power(effect_size=effectsize, nobs1=nobs, alpha=alpha)
```

如果你运行`print(power)`，你可以看到我们假设的 A/B 测试的统计功效大约是 0.65。这意味着我们预计在 A/B 测试中检测到效应的概率为 65%，而即使真实效应存在，我们的 A/B 测试没有发现它的概率为 35%。如果某个 A/B 测试预期费用较高，这样的赔率可能看起来不太理想；你需要根据自己对功效的最低接受标准做出决策。功效计算可以帮助你在规划阶段理解预期结果，并做好准备。一种常见的约定是，只批准预计功效至少为 80%的 A/B 测试。

你还可以使用我们在前一个代码片段中使用的相同`solve_power()`方法来“反向”计算统计功效：你可以从假定一个特定的功效水平开始，然后计算为了达到该统计功效水平所需的参数。例如，在以下代码片段中，我们定义了`power`、`alpha`和我们的效应大小，并运行`solve_power()`命令，这次不是计算功效，而是计算`observations`，即为了实现我们指定的功效水平， 每组所需的观测数量：

```py
analysis = TTestIndPower()
alpha = 0.05
effect = 0.5
power = 0.8
observations = analysis.solve_power(effect_size=effect, power=power, alpha=alpha)
```

如果你运行`print(observations)`，你会看到结果大约是 63.8。这意味着，如果我们希望在计划的 A/B 测试中达到 80%的统计功效，我们需要为两个组招募至少 64 个参与者。能够进行这些计算在 A/B 测试的规划阶段是非常有帮助的。

## 应用与高级考虑

到目前为止，我们只考虑了与营销电子邮件相关的 A/B 测试。但 A/B 测试适用于除了最佳电子邮件设计之外的各种商业挑战。A/B 测试最常见的应用之一是用户界面/体验设计。一个网站可能会随机将访问者分配到两个组（通常称为 A 组和 B 组），并向每组展示不同版本的网站。然后，该网站可以衡量哪个版本能带来更高的用户满意度、更高的收入、更多的链接点击、更多的停留时间，或者其他公司感兴趣的指标。整个过程可以完全自动化，这也使得今天顶尖科技公司能够进行高速、大规模的 A/B 测试。

电子商务公司进行测试，包括 A/B 测试，以确定产品定价。通过进行定价 A/B 测试，你可以衡量经济学家所说的*需求价格弹性*，即需求随价格变化的变化程度。如果你的 A/B 测试发现，当你提高价格时，需求变化非常小，那么你应该对所有人提高价格，利用他们更高的支付意愿。如果 A/B 测试发现，当你稍微提高价格时需求显著下降，那么你可以得出结论，客户对价格敏感，他们的购买决策很大程度上依赖于价格因素。如果客户对价格敏感并时刻考虑价格，他们很可能会对降价作出积极反应。如果是这样，你应该对所有人降价，并预计需求会大幅增加。一些企业必须依靠直觉或其他繁琐的计算来确定价格，但 A/B 测试使得确定正确价格变得相对简单。

电子邮件设计、用户界面设计和产品定价是*商业对消费者（B2C）*商业模型中的常见问题，在这种模型中，企业直接向消费者销售产品。B2C 场景非常适合进行 A/B 测试，因为 B2C 企业的客户、产品和交易数量通常比其他企业更高，因此我们可以获得更大的样本量和更强的统计能力。

这并不意味着商业对商业（B2B）公司不能进行 A/B 测试。事实上，A/B 测试在全球范围内以及许多领域已经被实践了几个世纪，尽管它过去仅被称为*科学*。例如，医学研究人员进行*随机对照试验*来测试新药，这种方法在本质上与 A/B 测试中的冠军/挑战者框架几乎相同。各类企业一直需要了解市场和客户，A/B 测试是一种自然、严谨的方式，几乎可以用来了解任何事情。

当你在业务中应用 A/B 测试时，你应该尽可能多地了解它，超越本章有限空间中的内容。一个你可能想深入研究的巨大领域是贝叶斯统计。一些数据科学家更倾向于使用贝叶斯方法，而不是显著性检验和*p*-值来测试 A/B 测试的成功。

另一个有趣且有用的主题是 A/B 测试中的*探索/开发权衡*。在这种权衡中，两个目标处于不断的张力之中：探索（例如，运行可能设计不佳的 A/B 测试以了解哪个最好）和开发（例如，仅发送表现最好的冠军电子邮件）。如果你的某个挑战者比冠军表现差很多，探索可能导致错失机会；你本可以直接向所有人发送冠军邮件。开发也可能导致错失机会，如果你的冠军不如另一个你还未测试的挑战者，因为你太专注于开发你的冠军而未进行必要的探索。

在运筹学研究中，你会发现大量关于*多臂老虎机问题*的研究，这是探索/开发困境的数学形式化。如果你真的有兴趣优化 A/B 测试，你可以了解一些研究人员提出的解决多臂老虎机问题的策略，以尽可能高效地进行 A/B 测试。

## A/B 测试的伦理

A/B 测试充满了困难的伦理问题。这可能让人感到惊讶，但请记住，A/B 测试是一种实验方法，我们故意改变人类受试者的体验，以便研究结果并为自己的利益服务。这意味着 A/B 测试是人类实验。想想其他人类实验的例子，看看为什么人们对它有伦理担忧：

1.  乔纳斯·索尔克开发了一种未经测试、前所未有的脊髓灰质炎疫苗，首先试验自己和家人，然后在数百万美国儿童中进行试验，以确保其有效。（它确实有效，并帮助消除了世界大部分地区的一种可怕的疾病。）

1.  我的祖母为她的孙子孙女做了一只派，观察我们对它的反应，然后第二天做了一只不同的派，检查我们是更积极还是更消极地反应。（两者都很美味。）

1.  一位教授伪装成学生，给 6300 位教授发送电子邮件，请他们安排时间与她交谈，谎称自己和意图，试图确定她的虚假身份是否会成为歧视的目标，以便她能够发表关于回复的论文。她没有为任何无意识参与研究的受试者提供补偿，既没有因欺骗或时间表干扰提供补偿，也没有事先获得他们同意作为实验对象。（这项研究的每一个细节都得到了大学伦理委员会的批准。）

1.  一家公司故意操控其用户的情感，以便更好地理解并向他们推销产品。

1.  约瑟夫·门格勒在奥斯维辛集中营对不愿意的受试者进行痛苦且致命的施虐实验。

1.  你执行一个 A/B 测试。

这份人体实验列表中的前五项实际上发生过，除第二项外，所有事件都引发了社会科学家们关于伦理的讨论。你将不得不决定第六项是否会发生，以及你将在涉及伦理问题时采取何种立场。由于“人体实验”涵盖的活动范围广泛，因此对所有形式的“人体实验”做出单一的伦理判断是不可能的。在决定我们的 A/B 测试是否让我们像我祖母或萨尔克那样成为英雄，像门格勒那样成为恶棍，或是介于两者之间时，我们必须考虑多个重要的伦理概念。

我们应考虑的第一个概念是同意。萨尔克在对他人进行大规模测试之前，首先在自己身上测试了疫苗。相比之下，门格勒则对被囚禁在集中营中的不愿受试者进行实验。知情同意总是使人体实验更具伦理性。在某些情况下，获得知情同意是不可行的。例如，如果我们进行关于哪种户外广告牌设计最有效的实验，我们无法从每个可能的受试者那里获得知情同意，因为全球任何人都有可能看到公共广告牌，而我们无法联系到每一个活着的人。

其他情况则形成一个大的灰色地带。例如，执行 A/B 测试的网站可能有一个“服务条款”部分，其中有细则和法律术语声明，每一个访问该网站的用户都同意在访问网站时成为实验对象（通过 A/B 测试用户界面特征）。这在技术上可能符合知情同意的定义，但几乎所有网站访客中，只有极少数人会浏览并理解这些条款。在灰色地带的情况下，考虑其他伦理概念是有帮助的。

与 A/B 测试相关的另一个重要伦理考量是风险。风险本身涉及两个方面：作为人体受试者参与的潜在不利影响，以及经历这些不利影响的可能性。萨尔克的疫苗有一个大的潜在不利影响——感染小儿麻痹症——但由于萨尔克的准备和知识，受试者遭遇这一风险的可能性极低。市场营销活动的 A/B 测试通常涉及的潜在不利影响极其微小，因为很难想象任何可能的负面后果，比如（例如）某人收到了蓝色而非黑色文字的营销邮件。对于受试者风险较低的实验，其伦理性高于高风险实验。

我们还应考虑从我们的实验中可能带来的潜在好处。萨尔克的疫苗实验具有（后来实现的）消除大多数地区脊髓灰质炎的潜力。A/B 测试旨在提高利润，而不是治愈疾病，因此你对其好处的判断将取决于你对公司利润的道德地位的看法。公司营销实验可能带来的唯一其他好处是对人类心理学的理解进展。实际上，企业营销从业者偶尔会将营销实验的结果发表在心理学期刊上，所以这并不鲜见。

伦理和哲学问题永远无法得出所有人都认同的最终结论。你可以自己决定是否认为 A/B 测试本质上是好的，就像萨尔克的疫苗实验一样，或本质上令人反感，就像门吉莱的恐怖实验一样。大多数人都同意，大多数在线 A/B 测试的风险极低，而且人们很少拒绝同意无害的 A/B 测试，这意味着当 A/B 测试得当时，它是道德上可以辩护的活动。不管怎样，你应该仔细考虑自己的情况，并得出自己的结论。

## 总结

本章讨论了 A/B 测试。我们从一个简单的 t 检验开始，然后探讨了在 A/B 测试过程中随机、非混杂数据收集的必要性。我们介绍了 A/B 测试的一些细微差别，包括冠军/挑战者框架和特威曼定律，以及伦理问题。在下一章，我们将讨论二元分类，这是任何数据科学家必备的技能。

## 第十六章：继续深入**

![image](img/common.jpg)

现在，你已经掌握了我认为的现代机器学习的一个很好的入门。我们涵盖了数据集构建、经典模型、模型评估和入门级深度学习，从传统的神经网络到卷积神经网络。这一小节旨在帮助你更进一步。

我们将关注短期的“下一步做什么”以及可能希望探索的长期选择分叉。我们还会包括在线资源，帮助你找到最新和最棒的内容（始终要意识到，网上的内容是短暂的）。然后是一个主观的会议列表，你可能希望参加这些会议。我们将以感谢和告别结束这一章和整本书。

### 深入探索卷积神经网络（CNN）

即使已经学习了四章内容，我们仍然仅仅触及了卷积神经网络能够做的事情的表面。部分原因是我们限制了自己的内容，以便你能够掌握基础知识；另一方面，由于我们有意识地决定不要求使用 GPU，也限制了内容的深度。用 GPU 训练复杂模型，通常比使用 CPU 快 20 到 25 倍。如果你的系统中有一块 GPU，最好是为深度学习应用设计的，那么可能性将大大增加。

我们开发的模型比较小，类似于 LeCun 在 1990 年代开发的原始 LeNet 模型。它们传达了基本的思想，但在很多情况下它们的表现并不会特别出色。现代的 CNN 有多种不同的版本，现在有了“标准”架构。借助 GPU，你可以探索这些更大的架构。

这些架构应该是你接下来要关注的：

+   ResNet

+   U-Net

+   VGG

+   DenseNet

+   起始

+   AlexNet

+   YOLO

幸运的是，我们介绍的 Keras 工具包（尽管我们几乎没有深入探讨）支持所有这些架构。对我来说，似乎特别有用的是 ResNet 和 U-Net。后者用于输入的语义分割，并且在医学影像中取得了广泛的成功。要在你的计算机的电源或硬盘崩溃之前，甚至不谈及心脏问题，成功训练这些架构中的任何一个，你确实需要一块 GPU。中到高端的游戏 GPU（例如来自 NVIDIA 的）将支持足够新的 CUDA 版本，你可以以不到 500 美元的价格获得一张显卡。真正的难点在于确保你的计算机能够支持这张显卡。电力需求很高，通常需要 600W 或以上的电源，并且需要一个支持双宽 PCIe 卡的插槽。选择内存而非性能；GPU 的内存越大，能够支持的模型也就越大。

即使你没有为系统升级 GPU，花时间研究上述架构也值得，了解它们的特别之处，并理解额外层的工作原理。查看 Keras 文档获取更多细节：[keras.io](http://keras.io)。

### 强化学习与无监督学习

本书专门讨论了有监督学习。在机器学习的三大主要分支中，有监督学习可能是最广泛使用的。回想一下马尔克斯兄弟，有监督学习就像是格劳乔，大家都记得他。这并不是对哈波和奇科的记忆不敬，也不是对机器学习的其他两个分支——强化学习和无监督学习的侮辱。

*强化学习*是目标导向的；它鼓励模型学习如何行为和行动，以最大化奖励。与有监督学习中学习如何将输入映射到特定输出类别不同，强化学习学习如何在当前情况下采取行动，以最大化整体目标，比如赢得一场比赛。许多与机器学习相关的令人印象深刻的新闻故事都涉及了强化学习。其中包括首个能够击败最强人类的雅达利 2600 游戏系统，以及世界围棋冠军输给 AlphaGo 的事件，更令人印象深刻的是 AlphaGo Zero 的成就，它从零开始掌握围棋，而没有从人类进行的数百万场游戏中学习。任何自动驾驶汽车系统可能都非常复杂，但可以肯定的是，强化学习是该系统的关键部分。

*无监督学习*指的是从未标记的输入数据中自主学习的系统。从历史上看，这意味着聚类，比如*k*-均值算法，它将未标记的特征向量进行分组，依据某种相似性度量。现在，人们可能认为无监督学习显得不那么重要，考虑到有监督学习和强化学习的巨大工作量。这仅仅是部分正确；许多有监督学习尝试使用未标记的数据（搜索*领域自适应*）。我们自己的学习中有多少是无监督的？一个被释放到外星世界的自主系统，如果能够学习到其创造者没有预见到需要了解的知识，可能会更成功。这表明了无监督学习的重要性。

### 生成对抗网络

*生成对抗网络（GANs）*于 2014 年横空出世，由深度学习研究员伊恩·古德费洛（Ian Goodfellow）提出。生成对抗网络迅速被誉为 20 年来机器学习领域最重要的进展（雅恩·勒昆（Yann LeCun）在 2016 年巴塞罗那 NIPS 会议上发表演讲时提到）。

最近关于能够生成无限数量高质量人类面孔的模型使用了 GANs（生成对抗网络）。同样，创建模拟场景和将一种风格（比如画作）转化为另一种风格（如照片）的模型也使用了 GANs。GANs 将生成网络（通常基于输入的随机设置生成输出）与判别网络（尝试学会区分真实输入与来自生成部分的输入）结合在一起。这两个网络共同训练，以便生成网络越来越擅长欺骗判别网络，而判别网络则越来越擅长学习如何辨别真伪。最终的结果是，生成网络能相当不错地输出你希望的内容。

对 GANs 的深入研究需要一本书，但它们绝对值得一看，至少可以帮助你形成对这一技术的直观理解。一个很好的入门点是特别流行的 GAN 架构——CycleGAN，它又衍生出了大量类似的模型。

### 递归神经网络

本书完全忽略的一个重要主题是 *递归神经网络 (RNNs)*。这些网络有反馈回路，非常适合处理像时间序列测量数据这样的序列——比如声音样本或视频帧。最常见的形式是 LSTM（长短期记忆网络）。递归网络被广泛应用于神经翻译模型中，比如 Google Translate，使得实时翻译数十种语言成为可能。

### 在线资源

机器学习的在线资源数不胜数，而且每天都在增加。以下是我认为有帮助且可能经得起时间考验的几个地方，顺序不分先后：

**Reddit 机器学习 (*[www.reddit.com/r/MachineLearning/](http://www.reddit.com/r/MachineLearning/)*)** 在这里查看最新的新闻和关于最新论文及研究的讨论。

**Arxiv (*[`arxiv.org/`](https://arxiv.org/)*)** 机器学习发展迅速，以至于大多数论文无法通过传统的同行评审过程发表在印刷期刊上。相反，几乎没有例外，研究人员和许多会议将所有论文上传到这个预印本服务器，提供免费访问最新的机器学习研究。浏览这些论文可能会让人感到不知所措。就个人而言，我使用 Arxiv 的手机应用，每周会浏览以下几个类别：计算机视觉与模式识别、人工智能、神经与进化计算和机器学习。仅这些类别每周发布的论文数量就令人印象深刻，也能很好地反映出这个领域的活跃程度。为了应对海量的论文，深度学习研究者 Andrej Karpathy 创建了实用的 Arxiv Sanity 网站，地址为 *[`www.arxiv-sanity.com/`](http://www.arxiv-sanity.com/)*。

**GitHub (*[`github.com/`](https://github.com/)*)** 这是一个人们可以托管软件项目的地方。你可以直接访问该网站，搜索机器学习项目，或者使用标准搜索引擎并在搜索时加入*github*关键词。随着机器学习项目的爆炸式增长，发生了一件美好的事情。绝大多数项目都是免费的，甚至可以商业使用。这通常包括完整的源代码和数据集。如果你在 Arxiv 上看到了一篇文章，通常可以在 GitHub 上找到其实现版本。

**Coursera (*[`www.coursera.org/`](https://www.coursera.org/)*)** Coursera 是一个在线课程的首选网站，其中绝大多数课程可以免费旁听。虽然也有其他网站，但 Coursera 由 Andrew Ng 共同创办，他的机器学习课程非常受欢迎。

**YouTube (*[`www.youtube.com/`](https://www.youtube.com/)*)** YouTube 目前已经是一个巨大的平台，里面充满了机器学习视频。观众需要谨慎选择，但通过一些挖掘和明智的筛选，你会在这里找到很多内容，包括最新最伟大的演示。搜索“Neural Networks for Machine Learning”，这是 Geoffrey Hinton 讲授的课程。

**Kaggle (*[`www.kaggle.com/`](https://www.kaggle.com/)*)** Kaggle 举办机器学习竞赛，并且是一个很好的数据集资源库。获胜者会详细介绍他们的模型和训练过程，提供了大量学习技术的机会。

### 会议

学习新语言的最佳方法之一是将自己沉浸在讲这种语言的文化中。机器学习也是如此。将自己沉浸在机器学习文化中的方法是参加会议。这可能会很昂贵，但许多学校和公司都认为这很重要，所以你可能能够获得参加的支持。

机器学习兴趣的爆炸性增长带来了一个新现象，这是我在其他学术领域未曾见过的：会议售罄。这在最大规模的会议上尤其如此，但其他会议也可能出现这种情况。如果你想参加，请注意时机非常重要。以下是一些会议，顺序无关紧要，且未提及许多优秀但规模较小的会议，请参考：

**NeurIPS（前身为 NIPS）** *Neural Information Processing Systems*（神经信息处理系统）的缩写，可能是最大规模的机器学习会议。在这个学术会议上，你可以期待看到最新的研究成果。近年来，NeurIPS 的门票很快售罄，2018 年甚至在 12 分钟内就售罄(!)，现在已转为抽签系统，所以除非你是某种形式的报告人，否则无法保证收到允许注册的黄金票邮件。通常在加拿大举办。

**ICML** *International Conference on Machine Learning*（国际机器学习会议）的缩写，可能是第二大年度会议。这个学术会议有多个分会场和工作坊，通常在欧洲或北美举办。

**ICLR** 国际学习表示会议是一个聚焦深度学习的学术会议。如果你想要深度技术讲解，关于深度学习的专业展示，这就是最好的地方。

**CVPR** 计算机视觉与模式识别大会是另一个大型会议，或许比 ICLR 稍微少些学术性。CVPR 非常受欢迎，并且不仅仅是以机器学习为导向。

**GTC** GPU 技术大会，由 NVIDIA 赞助，是一个技术大会，而非学术会议。每年 NVIDIA 的新硬件都会在这里展示，并且还会有一个大型展览，地点在加利福尼亚州圣荷西。

### 这本书

说市面上有一些机器学习书籍，就像说海里有一些鱼一样。然而，就深度学习而言，有一本书遥遥领先于其他：由 Ian Goodfellow、Yoshua Bengio 和 Aaron Courville 合著的*《深度学习》*（MIT 出版社，2016 年）。请见 *[`www.deeplearningbook.org/`](http://www.deeplearningbook.org/)*

*深度学习*是你想要认真成为机器学习研究员时应该参考的书籍。即使你不是，它也深入讲解了关键主题，并且具备数学严谨性。这本书并不是针对那些想提高使用某个工具包技能的人，而是为那些想了解机器学习背后的理论和相关数学的人而写的。实质上，这本书是一本高级本科教材——如果不是研究生级别的话，但这并不应该让你却步。总有一天，你会想看看这本书，所以把它放在脑海里，或者放在你的书架上。

### 《再见，谢谢所有的鱼》

我们已经走到了这本书的尽头。这里没有怪物，只有我们自己，还有通过前面章节的学习所获得的知识和直觉。感谢你们的坚持。对我来说，写这本书很有趣；我真心希望你阅读和思考这本书时也同样愉快。别停下来——把我们所学到的带走并付诸实践。如果你像我一样，你会在任何地方看到机器学习的应用。走出去，开始分类吧！

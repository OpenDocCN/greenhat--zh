## 第四章：从文件和 API 获取数据

![](img/chapterart.png)

访问数据并将其导入脚本是数据分析的第一步。本章介绍了几种从文件和其他来源导入数据到 Python 应用程序的方法，以及如何将数据导出到文件。你将学习如何访问不同类型文件的内容，包括那些存储在本地计算机上的文件，以及通过 HTTP 请求远程访问的文件。你还将了解如何通过发送请求到可以通过 URL 访问的 API 获取数据。最后，你将学习如何将不同类型的数据加载到 pandas DataFrame 中。

## 使用 Python 的 open() 函数导入数据

Python 的内置 `open()` 函数可以打开任何类型的文件，并在脚本中进行处理。该函数返回一个 `file` 对象，带有方法让你访问和操作文件中的内容。然而，如果文件包含某些特定格式的数据，如 CSV、JSON 或 HTML，你还需要导入相应的库来访问和操作这些数据。处理纯文本文件则不需要特殊的库；你可以直接使用 `open()` 返回的 `file` 对象的方法。

### 文本文件

文本文件（*.txt*）可能是你遇到的最常见文件类型。对 Python 来说，文本文件是一个字符串对象序列。每个字符串对象对应文本文件中的一行——即一系列以不可见的换行符（`\n`）或回车符结束的字符。

Python 提供了内置函数来处理文本文件，允许你执行读取、写入和追加操作。在本节中，我们将重点讲解如何从文本文件中读取数据。首先，在文本编辑器中输入以下段落，并将其保存为 *excerpt.txt* 文件。在第一个段落的结尾按两次 ENTER 键，创建段落之间的空行（但不要按 ENTER 键来分隔长行）：

```py
Today, robots can talk to humans using natural language, and they’re getting smarter. Even so, very few people understand how these robots work or how they might use these technologies in their own projects.

Natural language processing (NLP) – a branch of artificial intelligence that helps machines understand and respond to human language – is the key technology that lies at the heart of any digital assistant product.
```

对人类来说，段落包括两段文字，总共三句话。然而对 Python 来说，段落包括两行非空行和它们之间的一行空行。下面是如何将文件的全部内容读取到 Python 脚本中并打印出来：

```py
❶ path = "`/path/to/excerpt.txt`"
with open(❷ path, ❸ "r") as ❹ f:
❺ content = f.read()
print(content)
```

你首先指定文件的路径 ❶。你需要根据文件保存的位置，将 `/path/to/excerpt.txt` 替换为你自己的文件路径。你将文件路径作为第一个参数传递给 `open()` 函数 ❷。第二个参数控制文件的使用方式。默认情况下，这个参数是以文本模式读取文件，这意味着文件的内容只会以只读方式打开（不能编辑），并被当作字符串处理。你可以显式地指定 `"r"` 用于 *读取* ❸，但这并不是必须的。（传递 `"rt"` 会明确指定文本模式，并且指定读取方式。）`open()` 函数返回一个以指定模式打开的 `file` 对象 ❹。然后，你使用 `file` 对象的 `read()` 方法读取文件的全部内容 ❺。

```py`Using the `with` keyword with `open()` ensures that the `file` object is properly closed when you’re done with it even if an exception has been raised. Otherwise, you would need to call `f.close()` to close the file object and free up the system resources it consumes.    The following snippet reads in the same `/path/to/excerpt.txt` file content line by line, printing out only nonempty lines:    ``` path = "`/path/to/excerpt.txt`" with open(path,"r") as f: ❶ for i, line in enumerate(f):   ❷ if line.strip():       print(f"第 {i} 行: ", line.strip()) ```py    In this example, you add line numbers to each line with the `enumerate()` function ❶. Then you filter out empty lines with the `strip()` method ❷, which removes any whitespace from the start and end of the string object in each line. The blank second line of the text file contains only one character, a newline, which `strip()` removes. The second line thus becomes an empty string, which the `if` statement will evaluate as false and skip over. The output appears as follows. As you can see, there’s no `Line 1`:    ``` 第 0 行:  今天，机器人可以使用自然语言与人类对话，并且它们变得越来越智能。尽管如此，仍然很少有人理解这些机器人是如何工作的，或者他们如何在自己的项目中使用这些技术。 第 2 行:  自然语言处理（NLP）——一种帮助机器理解和回应人类语言的人工智能分支——是任何数字助手产品的核心技术。 ```py    Rather than print the lines, you can send them to a list by using a list comprehension:    ``` path = "`/path/to/excerpt.txt`" with open(path,"r") as f:   lst = [line.strip() for line in f if line.strip()] ```py    Each nonempty line will be a separate item in the list.    ### Tabular Data Files    A *tabular* data file is a file in which the data is structured into rows. Each row typically contains information about someone or something, as shown here:    ``` Jeff Russell, jeff.russell, sales Jane Boorman, jane.boorman, sales ```py    This is an example of a *flat file*, the most common type of tabular data file. The name comes from the structure: flat files contain simple-structured (flat) records, meaning the records do not contain nested structures, or subrecords. Typically, a flat file is a plaintext file in CSV or tab-separated values (TSV) format, containing one record per line. In *.csv* files, values in a record are separated by commas, while *.tsv* files use tabs as separators. Both formats are widely supported and are often used in data exchange to move tabular data between different applications.    The following is an example of data in CSV format, where the first line contains headers that describe the content of the lines below it. The header descriptions are used as *keys* to the data in the lines that follow. Copy this data into a text editor and save it as *cars.csv*:    ``` 年份,品牌,型号,价格 1997,福特,E350,3200.00 1999,雪佛兰,Venture,4800.00 1996,吉普,Grand Cherokee,4900.00 ```py    Python’s `open()` function can open *.csv* files in text mode. Then you can load the data into a Python object using a reader function from the `csv` module, as illustrated here:    ``` import csv path = "`/path/to/cars.csv`" with open(path, "r") as ❶ csv_file:   csv_reader = ❷ csv.DictReader(csv_file)   cars = []   for row in csv_reader:   ❸ cars.append(dict(row)) print(cars) ```py    The `open()` function returns a `file` object ❶, which you pass to a reader from the `csv` module. In this case, you use `DictReader()` ❷, which maps the data in each row to a dictionary using the corresponding headers from the first line as keys. You append these dictionaries to a list ❸. The resulting list of dictionaries looks like this:    ``` [  {'年份': '1997', '品牌': '福特', '型号': 'E350', '价格': '3200.00'},  {'年份': '1999', '品牌': '雪佛兰', '型号': 'Venture', '价格': '4800.00'},  {'年份': '1996', '品牌': '吉普', '型号': 'Grand Cherokee', '价格': '4900.00'} ] ```py    Alternatively, you might use the `csv` module’s `reader()` method to turn the *.csv* file into a list of lists, where each inner list represents a row, including the header row:    ``` import csv path = "cars.csv" with open(path, "r") as csv_file:   csv_reader = csv.reader(csv_file)   cars = []   for row in csv_reader:     cars.append(row) print(cars)  ```py    Here is the output:    ``` [   ['年份', '品牌', '型号', '价格']   ['1997', '福特', 'E350', '3200.00']   ['1999', '雪佛兰', 'Venture', '4800.00']   ['1996', '吉普', 'Grand Cherokee', '4900.00'] ] ```py    The `csv.DictReader()` and `csv.reader()` methods have an optional `delimiter` parameter, allowing you to specify the character that separates fields in your tabular data file. This parameter defaults to a comma, which is perfect for *.csv* files. However, by setting the parameter to `delimiter = "\t"`, you can read in the tab-separated data of *.tsv* files instead.    ### Binary Files    Text files are not the only types of files you may have to deal with. There are also executable (*.exe*) and image files (*.jpeg*, *.bmp*, and so on), which contain data in binary format, represented as a sequence of bytes. Since these bytes are typically intended to be interpreted as something other than text characters, you can’t open a binary file in text mode to access and manipulate its content. Instead, you must use the `open()` function’s binary mode.    The following example shows how to open an image file in binary mode. An attempt to do this in text mode would result in an error. You can run this code with any *.jpg* file on your computer:    ``` image = "`/path/to/file.jpg`" with open(image, ❶ "rb") as image_file:   content = ❷ image_file.read() ❸ print(len(content)) ```py    You instruct the `open()` function to open a file for reading in binary mode by passing in `"``rb"` as the second parameter ❶. The retrieved object, like an object retrieved in text mode, has the `read()` method to get the file’s content ❷. Here, the content is retrieved as a `bytes` object. In this example, you simply determine the number of bytes read from the file ❸.    ## Exporting Data to Files    After some processing, you may need to store data to a file so that you can use the data during the next execution of the script or import it into other scripts or applications. You may also need to store information in a file so that you or others can view it. For example, you may want to log information about the errors and exceptions generated by your application for later review.    You can create a new file from your Python script and write data to it, or you can write over the data in an existing file. We’ll explore an example of the latter here. Returning to the example from “Tabular Data Files,” suppose you need to modify a row in the *cars.csv* file, changing the price of a certain car. Recall that the data was read from the *cars.csv* file into a list of dictionaries named `cars`. To see the values of each dictionary in that list, you can run the following loop:    ``` for row in cars:   print(list(row.values())) ```py    In the loop body, you call the `values()` method on each dictionary in the list, thus converting the dictionary’s values into a `dict_values` object that can be easily converted into a list. Each list represents a row from the original *.csv* file, as shown here:    ``` ['1997', '福特', 'E350', '3200.00'] ['1999', '雪佛兰', 'Venture', '4800.00'] ['1996', '吉普', 'Grand Cherokee', '4900.00'] ```py    Suppose you need to update the `Price` field in the second row (for the Chevy Venture) and store this change in the original *cars.csv* file. You can make the change as follows:    ``` ❶ to_update = ['1999', '雪佛兰', 'Venture'] ❷ new_price = '4500.00' ❸ with open('`path/to/cars.csv`', 'w') as csvfile: ❹ fieldnames = cars[0].keys() ❺ writer = csv.DictWriter(csvfile, fieldnames=fieldnames)   writer.writeheader() ❻ for row in cars:     if set(to_update).issubset(set(row.values())):       row['价格'] = new_price     writer.writerow(row) ```py    First, you need a way to identify the row to be updated. You create a list called `to_update`, including enough of the row’s fields to uniquely identify the row ❶. Then, you specify the new value for the field to be changed as `new_price` ❷. Next, you open the file for writing, passing in the `'w'` flag to the `open()` function ❸. The `w` mode used here will overwrite the existing content of the file. You therefore must define the field names to be sent to the file ❹. These are the names of the keys used in a dictionary representing a car row.    Using the `csv.DictWriter()` function ❺, you create a writer object that will map the dictionaries from the `cars` list onto the output rows to be sent to the *cars.csv* file. In a loop over the dictionaries in the `cars` list ❻, you check if each row matches your specified identifier. If so, you update the row’s `Price` field. Finally, still within the loop, you write each row to the file using the `writer.writerow()` method.    Here’s what you will see in the *cars.csv* file after executing the script:    ``` 年份,品牌,型号,价格 1997,福特,E350,3200.00 1999,雪佛兰,Venture,4500.00 1996,吉普,Grand Cherokee,4900.00 ```py    As you can see, it looks like the original content, but the value of the `Price` field in the second row has been changed.    ## Accessing Remote Files and APIs    Several third-party Python libraries, including urllib3 and Requests, let you get data from a URL-accessible remote file. You can also use the libraries to send requests to HTTP APIs (those that use HTTP as their transfer protocol), many of which return the requested data in JSON format. Both urllib3 and Requests work by formulating custom HTTP requests based on information you input.    *HTTP (HyperText Transfer Protocol)*, the client/server protocol that forms the foundation of data exchange over the web, is structured as a series of requests and responses. The HTTP messages sent by a client are *requests*, while the answer messages returned by the server are *responses*. For example, whenever you click a link in your browser, the browser, acting as the client, sends an HTTP request to fetch the desired web page from the appropriate web server. You can do the same thing from a Python script. The script, acting as the client, obtains the requested data in the form of a JSON or XML document.    ### How HTTP Requests Work    There are several types of HTTP requests. The most common ones include `GET`, `POST`, `PUT`, and `DELETE`. These are also known as *HTTP request methods*, *HTTP commands*, or just *HTTP verbs*. The HTTP command in any HTTP request defines the action to be performed for a specified resource. For example, a `GET` request retrieves data from a resource, while a `POST` request pushes data to a destination.    An HTTP request also includes the request *target*, usually comprising a URL, and *headers*, the latter being fields that pass additional information along with the request. Some requests also include a *body*, which carries actual request data, such as a form submission. `POST` requests typically include a body, while `GET` requests don’t.    As an example, consider the following HTTP request:    ``` ❶ GET ❷ /api/books?bibkeys=ISBN%3A1718500521&format=json HTTP/1.1 ❸ Host: openlibrary.org ❹ User-Agent: python-requests/2.24.0 ❺ Accept-Encoding: gzip, deflate Accept: */* ❻ Connection: keep-alive ```py    This request uses the `GET` HTTP command ❶ to retrieve data from the given server (indicated as `Host` ❸) using the specified URI ❷. The remaining lines include other headers specifying additional information. The `User-Agent` request header identifies the application making the request and its version ❹. The `Accept` headers advertise which content types the client is able to understand ❺. The `Connection` header, set to `keep-alive` ❻, instructs the server to establish a persistent connection to the client, which allows for subsequent requests to be made.    In Python, you don’t have to fully understand the internal structure of HTTP requests to send them and receive responses. As you’ll learn in the following sections, libraries like Requests and urllib3 let you manipulate HTTP requests easily and efficiently, just by calling an appropriate method and passing the required parameters in to it.    With the help of the Requests library, the preceding HTTP request can be generated by a simple Python script as follows:    ``` import requests PARAMS = {'bibkeys':'ISBN:1718500521', 'format':'json'} requests.get('http://openlibrary.org/api/books', params = PARAMS) ```py    We’ll discuss the Requests library in detail shortly. For now, notice that the library saves you from having to set the headers of a request manually. It sets the default values behind the scenes, automatically generating a fully formatted HTTP request on your behalf based on just a few lines of code.    ### The urllib3 Library    urllib3 is a URL-handling library that lets you access and manipulate URL-accessible resources such as HTTP APIs, websites, and files. The library is designed to efficiently manipulate HTTP requests, using thread-safe connection pooling to minimize the resources needed on your server’s end. Compared to the Requests library, which we’ll discuss next, urllib3 requires more manual work, but it also gives you more direct control over the requests you prepare, which is useful when, for example, you need to customize pool behavior or explicitly decode HTTP responses.    #### Installing urllib3    Since urllib3 is a dependency of many popular Python packages, like Requests and `pip`, chances are you have it already installed in your Python environment. To check this, try to import it in a Python session. If you get a `ModuleNotFoundError`, you can install it explicitly with this command:    ``` $ **pip install urllib3** ```py    #### Accessing Files with urllib3    To see how to load data from a URL-accessible file with urllib3, you can use the *excerpt.txt* file you created earlier. To make this file accessible via a URL, you might put it into the document folder of an HTTP server running on your local host. Alternatively, use the following URL to obtain it from the GitHub repository accompanying this book: [`github.com/pythondatabook/sources/blob/main/ch4/excerpt.txt`](https://github.com/pythondatabook/sources/blob/main/ch4/excerpt.txt).    Run the following code, replacing the URL if necessary:    ``` import urllib3 ❶ http = urllib3.PoolManager() ❷ r = http.request('GET', '`http://localhost/excerpt.txt`') for i, line in enumerate(❸ r.data.decode('utf-8').split('\n')):   if line.strip():   ❹ print("第 %i 行: " %(i), line.strip()) ```py    First you create a `PoolManager` instance ❶, which is how urllib3 makes requests. After that, you make an HTTP request to the specified URL with the `request()` method of `PoolManager` ❷. The `request()` method returns an `HTTPResponse` object. You access the requested data through the `data` attribute of this object ❸. Then you output only nonempty lines, enumerating them at the beginning of each line ❹.    #### API Requests with urllib3    You can also use urllib3 to make requests to HTTP APIs. In the following example, you make a request to the News API ([`newsapi.org`](https://newsapi.org)), which searches for articles from a wide range of news sources, finding those that are most relevant to your request. Like many other APIs today, it requires you to pass in an API key with each request. You can get a developer API key for free at [`newsapi.org/register`](https://newsapi.org/register) after filling in a simple registration form. Then use this code to search for articles about the Python programming language:    ``` import json import urllib3 http = urllib3.PoolManager() r = http.request('GET', 'https://newsapi.org/v2/everything? ❶ q=Python         programming language& ❷ apiKey=`your_api_key_here`& ❸ pageSize=5') ❹ articles = json.loads(r.data.decode('utf-8')) for article in articles['articles']:   print(article['title'])   print(article['publishedAt'])   print(article['url'])   print() ```py    You pass in the search phrase as the `q` parameter in the request URL ❶. The only other required parameter to specify in the request URL is `apiKey` ❷, where you pass in your API key. There are also many other optional parameters. For example, you can specify the news sources or blogs you want articles from. In this particular example, you use `pageSize` to set the number of articles being retrieved to five ❸. The entire list of supported parameters can be found in the News API documentation at [`newsapi.org/docs`](https://newsapi.org/docs).    The `data` attribute of the `HTTPResponse` object returned by `request()` is a JSON document in the form of a `bytes` object. You decode it to a string, which you then pass to the `json.loads()` method to convert it into a dictionary ❹. To see how the data is structured in this dictionary, you might output it, but this step is omitted in this listing. If you looked at the output, you’d see that information about the articles can be found in the list called `articles` within the returned document, and each record in this list has the fields `title`, `publishedAt`, and `url`.    Using that information, you can print the retrieved list of articles in a more readable format, producing something like this:    ``` 一种表达编程挫折感的编程语言 2021-12-15T03:00:05Z https://hackaday.com/2021/12/14/a-programming-language-to-express-programming-frustration/  提高你企业潜力的 Python 学习之路 2021-12-24T16:30:00Z https://www.entrepreneur.com/article/403981  TIOBE 宣布 2021 年的编程语言是 Python 2022-01-08T19:34:00Z https://developers.slashdot.org/story/22/01/08/017203/tiobe-announces-that-the-programming-language-of-the-year-was-python  Python 是 2021 年 TIOBE 编程语言，究竟这一称号意味着什么？ 2022-01-04T12:28:01Z https://thenextweb.com/news/python-c-tiobe-programming-language-of-the-year-title-analysis  哪种编程语言或编译器更快 2021-12-18T02:15:28Z ```py    This example illustrated how to integrate the News API into a Python application using direct HTTP requests via the urllib3 library. An alternative would be to use the unofficial Python client library covered at [`newsapi.org/docs/client-libraries/python`](https://newsapi.org/docs/client-libraries/python).    ### The Requests Library    Requests is another popular URL-handling library that allows you to easily send HTTP requests. Requests uses urllib3 under the hood and makes it even easier to make requests and retrieve data. You can install the Requests library with the `pip` command:    ``` $ **pip install requests** ```py    HTTP verbs are implemented as the library’s methods (for example, `requests.get()` for an HTTP `GET` request). Here’s how to remotely access *excerpt.txt* with Requests. Replace the URL with the file’s GitHub link if necessary:    ``` import requests ❶ r = requests.get('`http://localhost/excerpt.txt`') for i, line in enumerate(❷ r.text.split('\n')):   if line.strip():   ❸ print("第 %i 行: " %(i), line.strip()) ```py    You make an HTTP `GET` request using the `requests.get()` method, passing the file’s URL as the parameter ❶. The method returns a `Response` object that includes the retrieved content in the `text` attribute ❷. Requests automatically decodes the retrieved content, making knowledgeable guesses about the encoding, so you don’t have to do it manually. Just as in the urllib3 example, you output only nonempty lines, adding a line number at the beginning of each ❸.    ## Moving Data to and from a DataFrame    pandas comes with a range of reader methods, each of which is designed to load data in a certain format and/or from a certain type of source. These methods allow you to load tabular data into a DataFrame with the help of a single call, thus making the imported dataset immediately ready for analysis. pandas also has methods for converting DataFrame data into other formats, such as JSON. This section explores examples of these methods for moving data to or from a DataFrame. We’ll also consider the pandas-datareader library, which is helpful for loading data from various online sources into pandas DataFrames.    ### Importing Nested JSON Structures    Since JSON has become the de facto standard for data interchange between applications, it’s important to have a way to quickly import a JSON document and convert it to a Python data structure. In the previous chapter, you saw an example of loading a simple, non-nested JSON structure into a DataFrame with the pandas `read_json()` reader. In this section, you’ll learn how to load a more complex, nested JSON document, like this one:    ``` data = [{"员工":"Jeff Russell",   "采购单":[{"单号":2608,"总数":35},          {"单号":2617,"总数":35},          {"单号":2620,"总数":139}   ]},   {"员工":"Jane Boorman",   "采购单":[{"单号":2621,"总数":95},         {"单号":2626,"总数":218}    ] }] ```py    As you can see, each entry in the JSON document begins with a simple-structured key-value pair with the key `Emp`, followed by a nested structure with the key `POs`. You can convert that hierarchical JSON structure into a tabular pandas DataFrame using the pandas library’s `json_normalize()` reader method, which takes a nested structure and flattens, or *normalizes*, it into a simple table. Here’s how:    ``` import json import pandas as pd df = pd.json_normalize(❶ data, ❷ "采购单", ❸ "员工").set_index([❹ "员工","单号"]) print(df) ```py    Apart from the JSON sample ❶ to be processed by `json_normalize()`, you also specify `POs` as the nested array to be flattened ❷ and `Emp` as the field to be used as part of the complex index in the resulting table ❸. In the same line of code, you set two columns as the index: `Emp` and `Pono` ❹. As a result, you will see the following pandas DataFrame:    ```  总数 员工          单号        Jeff Russell 2608     35  2617     35              2620    139 Jane Boorman 2621     95              2626    218 ```py    ### Converting a DataFrame to JSON    In practice, you may often need to perform the reverse operation, converting a pandas DataFrame into JSON. The following code converts our DataFrame back to the JSON sample from which it was originally generated:    ``` ❶ df = df.reset_index() json_doc = (❷ df.groupby(['员工'], as_index=True)              ❸ .apply(lambda x: x[['单号','总数']].to_dict('records'))              ❹ .reset_index()              ❺ .rename(columns={0:'采购单'})              ❻ .to_json(orient='records')) ```py    You start by dropping the two-column index of the DataFrame to make `Emp` and `Pono` regular columns ❶. Then, you use a composite one-liner to convert the DataFrame to a JSON document. First you apply a `groupby` operation to the DataFrame, grouping the rows by the `Emp` column ❷. You use `groupby()` in combination with `apply()` to apply a lambda function to each record in each group ❸. In the lambda expression, you specify the list of fields that you want to see in a row of the nested array associated with each `Emp` record. You use the `DataFrame.to_dict()` method with the `records` parameter to format the fields in the array as follows: `[{``column``:``value``}, ... , {``column``:``value``}]`, where each dictionary represents an order associated with a given employee.    At this point, you have a Series object with the index `Emp` and a column containing an array of orders associated with an employee. To give this column a name (in this case, `POs`), you need to convert the Series to a DataFrame. One simple way to do this is with `reset_index()` ❹. In addition to converting the Series to a DataFrame, `reset_index()` changes `Emp` from an index to a regular column, which will be important when you convert the DataFrame to JSON format. Finally, you explicitly set the name of the column containing the nested array (`POs`) using the DataFrame’s `rename()` method ❺ and turn the revised DataFrame into JSON ❻.    The content of `json_doc` looks as follows:    ``` [{"员工": "Jeff Russell",     "采购单": [{"单号": 2608, "总数": 35},       {"单号": 2617, "总数": 35},       {"单号": 2620, "总数": 139}     ]},   {"员工": "Jane Boorman",  "采购单": [{"单号": 2621, "总数": 95},       {"单号": 2626, "总数": 218}     ] }] ```py    To improve readability, you might print it out using the following command:    ``` print(json.dumps(json.loads(json_doc), indent=2)) ```py    ### Loading Online Data into a DataFrame with pandas-datareader    Several third-party libraries come with pandas-compatible reader methods for accessing data from a variety of online sources, such as Quandl ([`data.nasdaq.com`](https://data.nasdaq.com)) and Stooq ([`stooq.com`](https://stooq.com)). The most popular of these is pandas-datareader. At the time of writing, this library included 70 methods, each designed to load data from a certain source into a pandas DataFrame. Many of the library’s methods are wrappers for finance APIs, allowing you to easily get financial data in pandas format.    #### Installing pandas-datareader    Enter this command to install pandas-datareader:    ``` $ **pip install pandas-datareader** ```py    For descriptions of the library’s reader methods, consult the pandas-datareader documentation at [`pandas-datareader.readthedocs.io/en/latest/remote_data.html`](https://pandas-datareader.readthedocs.io/en/latest/remote_data.html). You can also print a list of the available methods with Python’s `dir()` function:    ``` import pandas_datareader.data as pdr print(dir(pdr)) ```py    #### Obtaining Data from Stooq    In the following example, you use the `get_data_stooq()` method to obtain S&P 500 index data for a specified period:    ``` import pandas_datareader.data as pdr spx_index = pdr.get_data_stooq('^SPX', '2022-01-03', '2022-01-10') print(spx_index) ```py    The `get_data_stooq()` method obtains data from Stooq, a free site that provides information on a number of market indexes. Pass in the ticker of the market index you want as the first parameter. The available options can be found at [`stooq.com/t`](https://stooq.com/t).    The obtained S&P 500 index data will typically appear in this format:    ```  开盘价     最高价     最低价   收盘价     成交量 日期                                                       2022-01-10  4655.34  4673.02  4582.24  4670.29
